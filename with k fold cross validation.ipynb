{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c7dc42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('test.xlsx', sheet_name='Sheet1')\n",
    "df['clean_text'] = (\n",
    "    df['reviewText'].str.lower()\n",
    "                     .str.replace(r'[^a-z0-9\\s]', ' ', regex=True)\n",
    "                     .str.replace(r'\\s+', ' ', regex=True)\n",
    "                     .str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca1dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1693c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.0.1\n",
      "CUDA: 11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA:\", torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ac17690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu118.html, https://data.pyg.org/whl/torch-2.0.1+cu118.html, https://data.pyg.org/whl/torch-2.0.1+cu118.html, https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
      "Collecting torch-scatter\n",
      "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.2%2Bpt20cu118-cp39-cp39-win_amd64.whl (3.7 MB)\n",
      "     ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.7 MB 131.3 kB/s eta 0:00:29\n",
      "     ---------------------------------------- 0.0/3.7 MB 131.3 kB/s eta 0:00:29\n",
      "     ---------------------------------------- 0.0/3.7 MB 131.3 kB/s eta 0:00:29\n",
      "     ---------------------------------------- 0.0/3.7 MB 131.3 kB/s eta 0:00:29\n",
      "     ---------------------------------------- 0.0/3.7 MB 131.3 kB/s eta 0:00:29\n",
      "      --------------------------------------- 0.1/3.7 MB 174.7 kB/s eta 0:00:21\n",
      "      --------------------------------------- 0.1/3.7 MB 174.7 kB/s eta 0:00:21\n",
      "      --------------------------------------- 0.1/3.7 MB 174.7 kB/s eta 0:00:21\n",
      "     - -------------------------------------- 0.1/3.7 MB 151.3 kB/s eta 0:00:25\n",
      "     - -------------------------------------- 0.1/3.7 MB 151.3 kB/s eta 0:00:25\n",
      "     -- ------------------------------------- 0.2/3.7 MB 276.8 kB/s eta 0:00:13\n",
      "     -- ------------------------------------- 0.2/3.7 MB 276.8 kB/s eta 0:00:13\n",
      "     -- ------------------------------------- 0.2/3.7 MB 276.8 kB/s eta 0:00:13\n",
      "     -- ------------------------------------- 0.2/3.7 MB 242.7 kB/s eta 0:00:15\n",
      "     -- ------------------------------------- 0.2/3.7 MB 248.7 kB/s eta 0:00:15\n",
      "     ---- ----------------------------------- 0.4/3.7 MB 451.3 kB/s eta 0:00:08\n",
      "     ---- ----------------------------------- 0.4/3.7 MB 451.3 kB/s eta 0:00:08\n",
      "     ---- ----------------------------------- 0.4/3.7 MB 451.3 kB/s eta 0:00:08\n",
      "     ---- ----------------------------------- 0.5/3.7 MB 418.0 kB/s eta 0:00:08\n",
      "     ------ --------------------------------- 0.6/3.7 MB 540.3 kB/s eta 0:00:06\n",
      "     --------- ------------------------------ 0.9/3.7 MB 741.9 kB/s eta 0:00:04\n",
      "     --------- ------------------------------ 0.9/3.7 MB 741.9 kB/s eta 0:00:04\n",
      "     --------- ------------------------------ 0.9/3.7 MB 741.9 kB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 0.9/3.7 MB 710.2 kB/s eta 0:00:04\n",
      "     -------------- ------------------------- 1.4/3.7 MB 986.5 kB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 1.6/3.7 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 1.8/3.7 MB 1.2 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 1.9/3.7 MB 1.2 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 1.9/3.7 MB 1.2 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 2.2/3.7 MB 1.3 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 3.2/3.7 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 3.6/3.7 MB 2.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 3.6/3.7 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.7/3.7 MB 2.1 MB/s eta 0:00:00\n",
      "Collecting torch-sparse\n",
      "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.18%2Bpt20cu118-cp39-cp39-win_amd64.whl (3.0 MB)\n",
      "     ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/3.0 MB 122.9 kB/s eta 0:00:24\n",
      "      --------------------------------------- 0.0/3.0 MB 122.9 kB/s eta 0:00:24\n",
      "      --------------------------------------- 0.0/3.0 MB 122.9 kB/s eta 0:00:24\n",
      "      --------------------------------------- 0.0/3.0 MB 122.9 kB/s eta 0:00:24\n",
      "     - -------------------------------------- 0.1/3.0 MB 152.8 kB/s eta 0:00:19\n",
      "     - -------------------------------------- 0.1/3.0 MB 169.3 kB/s eta 0:00:17\n",
      "     - -------------------------------------- 0.1/3.0 MB 169.3 kB/s eta 0:00:17\n",
      "     - -------------------------------------- 0.1/3.0 MB 169.3 kB/s eta 0:00:17\n",
      "     - -------------------------------------- 0.1/3.0 MB 169.3 kB/s eta 0:00:17\n",
      "     -- ------------------------------------- 0.2/3.0 MB 262.2 kB/s eta 0:00:11\n",
      "     -- ------------------------------------- 0.2/3.0 MB 270.6 kB/s eta 0:00:11\n",
      "     -- ------------------------------------- 0.2/3.0 MB 270.6 kB/s eta 0:00:11\n",
      "     -- ------------------------------------- 0.2/3.0 MB 270.6 kB/s eta 0:00:11\n",
      "     -- ------------------------------------- 0.2/3.0 MB 270.6 kB/s eta 0:00:11\n",
      "     ----- ---------------------------------- 0.4/3.0 MB 451.3 kB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 0.4/3.0 MB 451.3 kB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 0.4/3.0 MB 451.3 kB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 0.4/3.0 MB 451.3 kB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 0.4/3.0 MB 451.3 kB/s eta 0:00:06\n",
      "     ------------ --------------------------- 0.9/3.0 MB 741.3 kB/s eta 0:00:03\n",
      "     ------------ --------------------------- 0.9/3.0 MB 712.7 kB/s eta 0:00:03\n",
      "     ------------ --------------------------- 0.9/3.0 MB 712.7 kB/s eta 0:00:03\n",
      "     ------------ --------------------------- 0.9/3.0 MB 712.7 kB/s eta 0:00:03\n",
      "     ------------ --------------------------- 0.9/3.0 MB 712.7 kB/s eta 0:00:03\n",
      "     ------------------ --------------------- 1.4/3.0 MB 954.2 kB/s eta 0:00:02\n",
      "     ------------------------ --------------- 1.8/3.0 MB 1.2 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.8/3.0 MB 1.2 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.8/3.0 MB 1.2 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.8/3.0 MB 1.2 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 2.4/3.0 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.0/3.0 MB 1.7 MB/s eta 0:00:00\n",
      "Collecting torch-cluster\n",
      "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_cluster-1.6.3%2Bpt20cu118-cp39-cp39-win_amd64.whl (2.3 MB)\n",
      "     ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/2.3 MB 131.3 kB/s eta 0:00:18\n",
      "      --------------------------------------- 0.0/2.3 MB 131.3 kB/s eta 0:00:18\n",
      "      --------------------------------------- 0.0/2.3 MB 131.3 kB/s eta 0:00:18\n",
      "      --------------------------------------- 0.0/2.3 MB 131.3 kB/s eta 0:00:18\n",
      "      --------------------------------------- 0.0/2.3 MB 131.3 kB/s eta 0:00:18\n",
      "     - -------------------------------------- 0.1/2.3 MB 180.8 kB/s eta 0:00:13\n",
      "     - -------------------------------------- 0.1/2.3 MB 180.8 kB/s eta 0:00:13\n",
      "     - -------------------------------------- 0.1/2.3 MB 180.8 kB/s eta 0:00:13\n",
      "     - -------------------------------------- 0.1/2.3 MB 180.8 kB/s eta 0:00:13\n",
      "     - -------------------------------------- 0.1/2.3 MB 147.5 kB/s eta 0:00:16\n",
      "     --- ------------------------------------ 0.2/2.3 MB 283.2 kB/s eta 0:00:08\n",
      "     --- ------------------------------------ 0.2/2.3 MB 283.2 kB/s eta 0:00:08\n",
      "     --- ------------------------------------ 0.2/2.3 MB 283.2 kB/s eta 0:00:08\n",
      "     --- ------------------------------------ 0.2/2.3 MB 283.2 kB/s eta 0:00:08\n",
      "     --- ------------------------------------ 0.2/2.3 MB 238.4 kB/s eta 0:00:09\n",
      "     ------- -------------------------------- 0.4/2.3 MB 459.0 kB/s eta 0:00:05\n",
      "     ------- -------------------------------- 0.4/2.3 MB 459.0 kB/s eta 0:00:05\n",
      "     ------- -------------------------------- 0.4/2.3 MB 459.0 kB/s eta 0:00:05\n",
      "     ------- -------------------------------- 0.5/2.3 MB 402.9 kB/s eta 0:00:05\n",
      "     ------- -------------------------------- 0.5/2.3 MB 402.9 kB/s eta 0:00:05\n",
      "     --------------- ------------------------ 0.9/2.3 MB 751.4 kB/s eta 0:00:02\n",
      "     --------------- ------------------------ 0.9/2.3 MB 740.5 kB/s eta 0:00:02\n",
      "     --------------- ------------------------ 0.9/2.3 MB 740.5 kB/s eta 0:00:02\n",
      "     --------------- ------------------------ 0.9/2.3 MB 686.3 kB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 1.1/2.3 MB 751.4 kB/s eta 0:00:02\n",
      "     ------------------------------ --------- 1.8/2.3 MB 1.2 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.8/2.3 MB 1.2 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.8/2.3 MB 1.2 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.9/2.3 MB 1.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.3/2.3 MB 1.4 MB/s eta 0:00:00\n",
      "Collecting torch-spline-conv\n",
      "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_spline_conv-1.2.2%2Bpt20cu118-cp39-cp39-win_amd64.whl (641 kB)\n",
      "     ---------------------------------------- 0.0/641.1 kB ? eta -:--:--\n",
      "      --------------------------------------- 10.2/641.1 kB ? eta -:--:--\n",
      "      --------------------------------------- 10.2/641.1 kB ? eta -:--:--\n",
      "      --------------------------------------- 10.2/641.1 kB ? eta -:--:--\n",
      "      --------------------------------------- 10.2/641.1 kB ? eta -:--:--\n",
      "     -- ---------------------------------- 41.0/641.1 kB 131.3 kB/s eta 0:00:05\n",
      "     -- ---------------------------------- 41.0/641.1 kB 131.3 kB/s eta 0:00:05\n",
      "     -- ---------------------------------- 41.0/641.1 kB 131.3 kB/s eta 0:00:05\n",
      "     -- ---------------------------------- 41.0/641.1 kB 131.3 kB/s eta 0:00:05\n",
      "     -- ---------------------------------- 41.0/641.1 kB 131.3 kB/s eta 0:00:05\n",
      "     ----- ------------------------------- 92.2/641.1 kB 174.7 kB/s eta 0:00:04\n",
      "     ----- ------------------------------- 92.2/641.1 kB 174.7 kB/s eta 0:00:04\n",
      "     ----- ------------------------------- 92.2/641.1 kB 174.7 kB/s eta 0:00:04\n",
      "     ----- ------------------------------- 92.2/641.1 kB 174.7 kB/s eta 0:00:04\n",
      "     ----- ------------------------------ 102.4/641.1 kB 137.1 kB/s eta 0:00:04\n",
      "     ----------- ------------------------ 204.8/641.1 kB 276.8 kB/s eta 0:00:02\n",
      "     ----------- ------------------------ 204.8/641.1 kB 276.8 kB/s eta 0:00:02\n",
      "     ----------- ------------------------ 204.8/641.1 kB 276.8 kB/s eta 0:00:02\n",
      "     ----------- ------------------------ 204.8/641.1 kB 276.8 kB/s eta 0:00:02\n",
      "     ------------ ----------------------- 215.0/641.1 kB 229.9 kB/s eta 0:00:02\n",
      "     ------------------------ ----------- 440.3/641.1 kB 458.5 kB/s eta 0:00:01\n",
      "     ------------------------ ----------- 440.3/641.1 kB 458.5 kB/s eta 0:00:01\n",
      "     ------------------------ ----------- 440.3/641.1 kB 458.5 kB/s eta 0:00:01\n",
      "     ------------------------ ----------- 440.3/641.1 kB 458.5 kB/s eta 0:00:01\n",
      "     ------------------------- ---------- 450.6/641.1 kB 385.9 kB/s eta 0:00:01\n",
      "     ------------------------------------ 641.1/641.1 kB 538.2 kB/s eta 0:00:00\n",
      "Collecting torch-geometric\n",
      "  Obtaining dependency information for torch-geometric from https://files.pythonhosted.org/packages/03/9f/157e913626c1acfb3b19ce000b1a6e4e4fb177c0bc0ea0c67ca5bd714b5a/torch_geometric-2.6.1-py3-none-any.whl.metadata\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "     ---------------------------------------- 0.0/63.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 63.1/63.1 kB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch-sparse) (1.10.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch-geometric) (3.8.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch-geometric) (2023.6.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\utkid\\appdata\\roaming\\python\\python39\\site-packages (from torch-geometric) (1.23.5)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch-geometric) (5.9.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch-geometric) (3.1.1)\n",
      "Requirement already satisfied: requests in c:\\users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch-geometric) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch-geometric) (4.65.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages (from aiohttp->torch-geometric) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages (from aiohttp->torch-geometric) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages (from aiohttp->torch-geometric) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages (from aiohttp->torch-geometric) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages (from aiohttp->torch-geometric) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages (from aiohttp->torch-geometric) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages (from aiohttp->torch-geometric) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages (from jinja2->torch-geometric) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->torch-geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->torch-geometric) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->torch-geometric) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.4/1.1 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.0/1.1 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 10.3 MB/s eta 0:00:00\n",
      "Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster, torch-geometric\n",
      "Successfully installed torch-cluster-1.6.3+pt20cu118 torch-geometric-2.6.1 torch-scatter-2.1.2+pt20cu118 torch-sparse-0.6.18+pt20cu118 torch-spline-conv-1.2.2+pt20cu118\n"
     ]
    }
   ],
   "source": [
    "# Paste into a notebook cell (with the bang) or your terminal.\n",
    "# Replace cu118 with whatever torch.version.cuda reports (e.g. cu121)\n",
    "!pip install --no-cache-dir \\\n",
    "    torch-scatter     -f https://data.pyg.org/whl/torch-2.0.1+cu118.html \\\n",
    "    torch-sparse      -f https://data.pyg.org/whl/torch-2.0.1+cu118.html \\\n",
    "    torch-cluster     -f https://data.pyg.org/whl/torch-2.0.1+cu118.html \\\n",
    "    torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.1+cu118.html \\\n",
    "    torch-geometric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10e1ebcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "C:\\Users\\utkid\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score,\n",
    "    recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3a3bb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding BERT…\n"
     ]
    }
   ],
   "source": [
    "# --- 2) BERT embeddings ---\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "bert = BertModel.from_pretrained('bert-base-multilingual-cased').to(device)\n",
    "bert.eval()\n",
    "def encode(texts, batch=16, maxlen=200):\n",
    "    embs=[]\n",
    "    for i in range(0,len(texts),batch):\n",
    "        enc = tokenizer(texts[i:i+batch], padding=True,\n",
    "                        truncation=True, max_length=maxlen,\n",
    "                        return_tensors='pt').to(device)\n",
    "        with torch.no_grad():\n",
    "            out = bert(**enc)\n",
    "        embs.append(out.last_hidden_state[:,0,:].cpu())\n",
    "    return torch.cat(embs,0)\n",
    "print(\"Encoding BERT…\")\n",
    "rev_emb = encode(df['clean_text'].tolist())  # (N,768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ad19fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import contextlib\n",
    "import threadpoolctl\n",
    "\n",
    "# 1) Force single‑thread BLAS/MKL:\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"]     = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"]     = \"1\"\n",
    "\n",
    "# 2) Stub out threadpoolctl’s internals so it never introspects libraries\n",
    "threadpoolctl._ThreadpoolInfo    = lambda *args, **kwargs: []\n",
    "threadpoolctl.threadpool_limits  = lambda *args, **kwargs: contextlib.nullcontext()\n",
    "\n",
    "# Now it's safe to import sklearn and run KMeans without errors\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "046383be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN graph edges: 1406254\n"
     ]
    }
   ],
   "source": [
    "# --- 3) Build a kNN graph with PyG (sparse, GPU‑friendly) ---\n",
    "from torch_geometric.nn import knn_graph\n",
    "\n",
    "# rev_emb: torch.Tensor shape [N, 768] (on device or CPU)\n",
    "# choose k (e.g. 10 nearest neighbors)\n",
    "k = 10\n",
    "\n",
    "# loop=False omits self‑loops; set to True if you want them\n",
    "edge_index = knn_graph(\n",
    "    x=rev_emb.to(device),\n",
    "    k=k,\n",
    "    loop=False\n",
    ")\n",
    "\n",
    "print(\"kNN graph edges:\", edge_index.size(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "605bebec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User feature tensor shape: torch.Size([140625, 3])\n",
      "Item feature tensor shape: torch.Size([140625, 3])\n"
     ]
    }
   ],
   "source": [
    "# --- 4) User / Item Feature Extraction (fixed column names) ---\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 4.0) (Re)load your DataFrame if needed; for JSON:\n",
    "# df = pd.read_json('Cell_Phones_and_Accessories.json', lines=True)\n",
    "\n",
    "# 4.1) Per‑user statistics (group by reviewerID)\n",
    "u_stats = (\n",
    "    df\n",
    "    .groupby('reviewerID')['overall']\n",
    "    .agg(count_u='count', mean_u='mean', std_u='std')\n",
    "    .fillna(0)\n",
    ")\n",
    "df = df.join(u_stats, on='reviewerID')\n",
    "\n",
    "# 4.2) Per‑item statistics (group by asin)\n",
    "i_stats = (\n",
    "    df\n",
    "    .groupby('asin')['overall']\n",
    "    .agg(count_i='count', mean_i='mean', std_i='std')\n",
    "    .fillna(0)\n",
    ")\n",
    "df = df.join(i_stats, on='asin')\n",
    "\n",
    "# 4.3) Normalize the new features\n",
    "user_cols = ['count_u', 'mean_u', 'std_u']\n",
    "item_cols = ['count_i', 'mean_i', 'std_i']\n",
    "scaler_u = StandardScaler()\n",
    "scaler_i = StandardScaler()\n",
    "\n",
    "df[user_cols] = scaler_u.fit_transform(df[user_cols])\n",
    "df[item_cols] = scaler_i.fit_transform(df[item_cols])\n",
    "\n",
    "# 4.4) Convert to PyTorch tensors\n",
    "user_feats = torch.tensor(df[user_cols].values, dtype=torch.float)\n",
    "item_feats = torch.tensor(df[item_cols].values, dtype=torch.float)\n",
    "\n",
    "print(\"User feature tensor shape:\", user_feats.shape)\n",
    "print(\"Item feature tensor shape:\", item_feats.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33c898bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5) Labels & masks ---\n",
    "y = torch.tensor(df['class'].values, dtype=torch.long)\n",
    "idx = np.arange(N)\n",
    "# 70% train, 15% val, 15% test stratified\n",
    "train_idx, tmp_idx = train_test_split(idx, stratify=y.numpy(),\n",
    "                                      test_size=0.3, random_state=42)\n",
    "val_idx,   test_idx= train_test_split(tmp_idx, stratify=y[tmp_idx].numpy(),\n",
    "                                      test_size=0.5, random_state=42)\n",
    "mask = lambda arr: torch.tensor(np.isin(idx, arr), dtype=torch.bool)\n",
    "\n",
    "train_mask = mask(train_idx)\n",
    "val_mask   = mask(val_idx)\n",
    "test_mask  = mask(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90b3a5d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rev_emb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 17\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Make sure these variables exist:\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# rev_emb      : torch.Tensor of shape [N, 768]\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# edge_index   : torch.LongTensor of shape [2, E]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# test_mask    : torch.BoolTensor of shape [N]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# device       : torch.device('cuda:0') or torch.device('cpu')\u001b[39;00m\n\u001b[0;32m     16\u001b[0m data \u001b[38;5;241m=\u001b[39m Data(\n\u001b[1;32m---> 17\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[43mrev_emb\u001b[49m\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m     18\u001b[0m     edge_index\u001b[38;5;241m=\u001b[39medge_index\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m     19\u001b[0m     user_x\u001b[38;5;241m=\u001b[39muser_feats\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m     20\u001b[0m     item_x\u001b[38;5;241m=\u001b[39mitem_feats\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m     21\u001b[0m     y\u001b[38;5;241m=\u001b[39my\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m     22\u001b[0m     train_mask\u001b[38;5;241m=\u001b[39mtrain_mask\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m     23\u001b[0m     val_mask\u001b[38;5;241m=\u001b[39mval_mask\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m     24\u001b[0m     test_mask\u001b[38;5;241m=\u001b[39mtest_mask\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNum nodes:\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m.\u001b[39mnum_nodes)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rev_emb' is not defined"
     ]
    }
   ],
   "source": [
    "# --- 6) Build PyG Data (fixed variable names) ---\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Make sure these variables exist:\n",
    "# rev_emb      : torch.Tensor of shape [N, 768]\n",
    "# edge_index   : torch.LongTensor of shape [2, E]\n",
    "# user_feats   : torch.Tensor of shape [N, 3]   (count_u, mean_u, std_u)\n",
    "# item_feats   : torch.Tensor of shape [N, 3]   (count_i, mean_i, std_i)\n",
    "# y            : torch.LongTensor of shape [N]  (0 or 1 labels)\n",
    "# train_mask   : torch.BoolTensor of shape [N]\n",
    "# val_mask     : torch.BoolTensor of shape [N]\n",
    "# test_mask    : torch.BoolTensor of shape [N]\n",
    "# device       : torch.device('cuda:0') or torch.device('cpu')\n",
    "\n",
    "data = Data(\n",
    "    x=rev_emb.to(device),\n",
    "    edge_index=edge_index.to(device),\n",
    "    user_x=user_feats.to(device),\n",
    "    item_x=item_feats.to(device),\n",
    "    y=y.to(device),\n",
    "    train_mask=train_mask.to(device),\n",
    "    val_mask=val_mask.to(device),\n",
    "    test_mask=test_mask.to(device)\n",
    ")\n",
    "\n",
    "print(data)\n",
    "print(\"Num nodes:\", data.num_nodes)\n",
    "print(\"Num edges:\", data.num_edges)\n",
    "print(\"Train/Val/Test sizes:\", \n",
    "      data.train_mask.sum().item(), \n",
    "      data.val_mask.sum().item(), \n",
    "      data.test_mask.sum().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "467c406d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 1.1) Save the Data object\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mdata\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_amazon_data.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved processed data to processed_amazon_data.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 1.2) Later (in a fresh notebook), just do:\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# After Step 6, once `data` is fully built:\n",
    "import torch\n",
    "\n",
    "# 1.1) Save the Data object\n",
    "torch.save(data, 'processed_amazon_data.pt')\n",
    "print(\"Saved processed data to processed_amazon_data.pt\")\n",
    "\n",
    "# 1.2) Later (in a fresh notebook), just do:\n",
    "data = torch.load('processed_amazon_data.pt')\n",
    "data = data.to(device)   # move all tensors to GPU if needed\n",
    "print(data)\n",
    "\n",
    "\n",
    "# 2.1) Save only weights\n",
    "torch.save(model.state_dict(), 'gdfn_efficient_weights.pth')\n",
    "print(\"Model weights saved to gdfn_efficient_weights.pth\")\n",
    "\n",
    "# 2.2) And to reload later:\n",
    "model = GDFN_Efficient(768, 64, len(user_cols), len(item_cols), 128).to(device)\n",
    "model.load_state_dict(torch.load('gdfn_efficient_weights.pth'))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bbb772a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7) Define GDFN model with GCNConv ---\n",
    "class GDFN_PyG(nn.Module):\n",
    "    def __init__(self, rev_dim, gcn_dim, u_dim, i_dim, fusion_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(rev_dim, gcn_dim)\n",
    "        self.conv2 = GCNConv(gcn_dim, gcn_dim)\n",
    "        self.u_lin  = nn.Sequential(nn.Linear(u_dim, gcn_dim), nn.ReLU())\n",
    "        self.i_lin  = nn.Sequential(nn.Linear(i_dim, gcn_dim), nn.ReLU())\n",
    "        self.fuse  = nn.Sequential(nn.Linear(gcn_dim**3, fusion_dim), nn.ReLU())\n",
    "        self.cls   = nn.Linear(fusion_dim, 2)\n",
    "    def forward(self, x, edge_index, ux, ix):\n",
    "        h = F.relu(self.conv1(x, edge_index))\n",
    "        h = F.relu(self.conv2(h, edge_index))\n",
    "        u = self.u_lin(ux)\n",
    "        i = self.i_lin(ix)\n",
    "        B,d = h.size()\n",
    "        h3 = h.view(B,d,1,1); u3 = u.view(B,1,d,1); i3 = i.view(B,1,1,d)\n",
    "        fused = (h3*u3*i3).view(B,-1)\n",
    "        fused = self.fuse(fused)\n",
    "        return self.cls(fused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5dfce093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10  Loss=0.6598  TrainAcc=0.657  ValAcc=0.657\n",
      "Epoch 20  Loss=0.6481  TrainAcc=0.665  ValAcc=0.665\n",
      "Epoch 30  Loss=0.6326  TrainAcc=0.725  ValAcc=0.726\n",
      "Epoch 40  Loss=0.6098  TrainAcc=0.790  ValAcc=0.793\n",
      "Epoch 50  Loss=0.5766  TrainAcc=0.841  ValAcc=0.844\n",
      "\n",
      "Test Metrics:\n",
      "  Accuracy : 0.8382\n",
      "  Precision: 0.8041\n",
      "  Recall   : 0.9963\n",
      "  F1       : 0.8899\n",
      "  Auc      : 0.9603\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score,\n",
    "    recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "# --- Efficient GDFN: elementwise triple product fusion ---\n",
    "class GDFN_Efficient(nn.Module):\n",
    "    def __init__(self, rev_dim, gcn_dim, u_dim, i_dim, fusion_dim, num_classes=2):\n",
    "        super().__init__()\n",
    "        # two‑layer GCN\n",
    "        self.conv1 = GCNConv(rev_dim, gcn_dim)\n",
    "        self.conv2 = GCNConv(gcn_dim, gcn_dim)\n",
    "        # user/item MLPs\n",
    "        self.user_lin = nn.Sequential(nn.Linear(u_dim, gcn_dim), nn.ReLU())\n",
    "        self.item_lin = nn.Sequential(nn.Linear(i_dim, gcn_dim), nn.ReLU())\n",
    "        # fuse & classify\n",
    "        self.fuse_lin = nn.Sequential(nn.Linear(gcn_dim, fusion_dim), nn.ReLU())\n",
    "        self.cls      = nn.Linear(fusion_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, ux, ix):\n",
    "        # GCN on reviews\n",
    "        h = F.relu(self.conv1(x, edge_index))\n",
    "        h = F.relu(self.conv2(h, edge_index))\n",
    "        # project user/item\n",
    "        u = self.user_lin(ux)\n",
    "        i = self.item_lin(ix)\n",
    "        # element‑wise triple product (N, d)\n",
    "        fused = h * u * i\n",
    "        # fuse down to fusion_dim\n",
    "        fused = self.fuse_lin(fused)\n",
    "        return self.cls(fused)  # (N, num_classes)\n",
    "\n",
    "# --- Instantiate & train/evaluate as before, just swapping in GDFN_Efficient ---\n",
    "model = GDFN_Efficient(\n",
    "    data.x.size(1),   # 768\n",
    "    64,               # gcn_dim\n",
    "    len(user_cols),   # user feature dim\n",
    "    len(item_cols),   # item feature dim\n",
    "    128               # fusion_dim\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out  = model(data.x, data.edge_index, data.user_x, data.item_x)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate(mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out   = model(data.x, data.edge_index, data.user_x, data.item_x)\n",
    "        probs = F.softmax(out, dim=1)[mask,1].cpu().numpy()\n",
    "        preds = out[mask].argmax(1).cpu().numpy()\n",
    "        true  = data.y[mask].cpu().numpy()\n",
    "    return {\n",
    "        'accuracy' : accuracy_score(true, preds),\n",
    "        'precision': precision_score(true, preds),\n",
    "        'recall'   : recall_score(true, preds),\n",
    "        'f1'       : f1_score(true, preds),\n",
    "        'auc'      : roc_auc_score(true, probs)\n",
    "    }\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, 51):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        tr = evaluate(data.train_mask)\n",
    "        vl = evaluate(data.val_mask)\n",
    "        print(f\"Epoch {epoch:02d}  Loss={loss:.4f}  \"\n",
    "              f\"TrainAcc={tr['accuracy']:.3f}  ValAcc={vl['accuracy']:.3f}\")\n",
    "\n",
    "# Final test\n",
    "tm = evaluate(data.test_mask)\n",
    "print(\"\\nTest Metrics:\")\n",
    "for k,v in tm.items():\n",
    "    print(f\"  {k.capitalize():<9}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6859ecbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
